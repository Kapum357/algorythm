"use client";

import {useEffect, useRef, useState} from "react";
import styles from "./VoiceAssistant.module.css";
import TTSButton from "./TTSButton";

export default function VoiceAssistant({ compact = false }) {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [response, setResponse] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [error, setError] = useState(null);
  const [isSupported, setIsSupported] = useState(true);
  
  const recognitionRef = useRef(null);
  const [interimTranscript, setInterimTranscript] = useState("");

  useEffect(() => {
      if ("undefined" === typeof window) {
          return;
      }
    
    // Verificar soporte de Web Speech API
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      setIsSupported(false);
      setError("Tu navegador no soporta reconocimiento de voz. Usa Chrome, Edge o Safari.");
      return;
    }

    // Inicializar reconocimiento de voz
    const recognition = new SpeechRecognition();
    recognition.lang = "es-CO"; // EspaÃ±ol de Colombia
    recognition.continuous = false; // Parar despuÃ©s de una frase
    recognition.interimResults = true; // Mostrar resultados parciales
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      console.log("ğŸ¤ Escuchando...");
      setIsListening(true);
      setError(null);
      setInterimTranscript("");
    };

    recognition.onresult = (event) => {
      let interim = "";
      let final = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          final += transcript;
        } else {
          interim += transcript;
        }
      }

      setInterimTranscript(interim);
      if (final) {
        console.log("ğŸ“ TranscripciÃ³n final:", final);
        setTranscript(final);
        processVoiceCommand(final);
      }
    };

    recognition.onerror = (event) => {
      // Normalizar la clave de error (event.error puede ser string o un objeto)
      const rawErr = event?.error;
        const errKey = "string" === typeof rawErr
        ? rawErr
        : (rawErr && (rawErr.name || rawErr.message)) || String(rawErr);

      console.error("âŒ Error de reconocimiento:", errKey, event);
      setIsListening(false);

      const errorMessages = {
        "no-speech": "No se detectÃ³ ninguna voz. Intenta de nuevo.",
        "audio-capture": "No se pudo acceder al micrÃ³fono. Verifica los permisos.",
        "not-allowed": "Permiso de micrÃ³fono denegado. HabilÃ­talo en la configuraciÃ³n del navegador.",
        "network": "Error de conexiÃ³n con el servicio de reconocimiento. Verifica tu internet.",
        "aborted": "Reconocimiento cancelado.",
      };

      // Mensaje por defecto si no estÃ¡ mapeado
      const friendly = errorMessages[errKey] || `Error de reconocimiento: ${errKey}`;
      setError(friendly);

      // Intento de reintento automÃ¡tico sÃ³lo para errores transitorios de red (una vez)
        if ("network" === errKey) {
        // SÃ³lo reintentar si el navegador reporta estar online
        if (navigator.onLine) {
          console.log("ğŸ” Reintentando reconocimiento por error de red en 1.5s...");
          setTimeout(() => {
            try {
              recognition.start();
            } catch (e) {
              console.warn("No se pudo reanudar reconocimiento:", e);
            }
          }, 1500);
        }
      }
    };

    recognition.onend = () => {
      console.log("ğŸ”‡ Reconocimiento detenido");
      setIsListening(false);
      setInterimTranscript("");
    };

    recognitionRef.current = recognition;

    return () => {
      // Al desmontar, detener el reconocimiento si estÃ¡ activo. Proteger con try/catch
      try {
          if (recognitionRef.current && 'function' === typeof recognitionRef.current.stop) {
          recognitionRef.current.stop();
        }
      } catch (err) {
        // Evitar lanzar errores durante el unmount
        console.warn('Warning: no se pudo detener el reconocimiento al desmontar:', err);
      }
    };
  }, []);

  const startListening = () => {
      if (!recognitionRef.current || isListening) {
          return;
      }
    
    setTranscript("");
    setResponse("");
    setError(null);
    
    try {
      recognitionRef.current.start();
    } catch (err) {
      console.error("Error al iniciar reconocimiento:", err);
      setError("No se pudo iniciar el reconocimiento de voz. Intenta de nuevo.");
    }
  };

  const stopListening = () => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop();
    }
  };

  const processVoiceCommand = async (text) => {
    setIsProcessing(true);
    setError(null);

    try {
      const response = await fetch("/api/ollama/voice", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ 
          query: text,
          context: "climate-resilience-assistant" 
        }),
      });

      if (!response.ok) {
        throw new Error(`Error del servidor: ${response.status}`);
      }

      const data = await response.json();
      
      if (data.success) {
        setResponse(data.response);
      } else {
        throw new Error(data.error || "Error procesando la consulta");
      }
    } catch (err) {
      console.error("Error procesando comando de voz:", err);
      setError(`Error: ${err.message}`);
      setResponse("Lo siento, no pude procesar tu consulta. Intenta de nuevo.");
    } finally {
      setIsProcessing(false);
    }
  };

  if (!isSupported) {
    return (
      <div className={styles.container}>
        <div className={styles.unsupported}>
          <div className={styles.icon}>ğŸš«</div>
          <h3 className="text-h6">Voz no soportada</h3>
          <p className="text-body2">{error}</p>
        </div>
      </div>
    );
  }

  if (compact) {
    return (
      <div className={styles.compactContainer}>
        <button
          onClick={isListening ? stopListening : startListening}
          disabled={isProcessing}
          className={`${styles.compactBtn} ${isListening ? styles.listening : ""}`}
          aria-label={isListening ? "Detener escucha" : "Activar asistente de voz"}
        >
          {isListening ? "ğŸ™ï¸" : "ğŸ¤"}
        </button>
        
        {(transcript || response) && (
          <div className={styles.compactPopup}>
            {transcript && (
              <div className={styles.compactTranscript}>
                <strong>TÃº:</strong> {transcript}
              </div>
            )}
            {response && (
              <div className={styles.compactResponse}>
                <strong>Asistente:</strong> {response}
              </div>
            )}
          </div>
        )}
      </div>
    );
  }

  return (
    <div className={styles.container}>
      <div className={styles.card}>
        <div className={styles.header}>
          <div className={styles.iconLarge}>
            {isListening ? "ğŸ™ï¸" : isProcessing ? "ğŸ¤–" : "ğŸ¤"}
          </div>
          <h3 className="text-h5">Asistente de Voz DIR-Soacha</h3>
          <p className="text-body2">
            Pregunta sobre alertas climÃ¡ticas, riesgos de inundaciÃ³n y protocolos de emergencia
          </p>
        </div>

        <div className={styles.controls}>
          <button
            onClick={isListening ? stopListening : startListening}
            disabled={isProcessing}
            className={`${styles.micBtn} ${isListening ? styles.active : ""}`}
            aria-label={isListening ? "Detener escucha" : "Iniciar escucha"}
          >
            {isListening ? (
              <>
                <span className={styles.pulse}></span>
                ğŸ™ï¸ Escuchando...
              </>
            ) : isProcessing ? (
              "â³ Procesando..."
            ) : (
              "ğŸ¤ Presiona para hablar"
            )}
          </button>
        </div>

        {interimTranscript && (
          <div className={styles.interim}>
            <span className={styles.label}>Transcribiendo:</span>
            <span className={styles.text}>{interimTranscript}</span>
          </div>
        )}

        {transcript && (
          <div className={styles.transcript}>
            <div className={styles.label}>
              <strong>ğŸ—£ï¸ TÃº preguntaste:</strong>
            </div>
            <p className="text-body1">{transcript}</p>
          </div>
        )}

        {response && (
          <div className={styles.response}>
            <div className={styles.labelRow}>
              <div className={styles.label}>
                <strong>ğŸ¤– Respuesta del asistente:</strong>
              </div>
              <TTSButton text={response} label="Escuchar respuesta" small />
            </div>
            <p className="text-body1">{response}</p>
          </div>
        )}

        {error && (
          <div className={styles.error}>
            <strong>âš ï¸ Error:</strong> {error}
          </div>
        )}

        <div className={styles.examples}>
          <p className="text-caption"><strong>Ejemplos de preguntas:</strong></p>
          <ul className="text-caption">
            <li>&ldquo;Â¿CuÃ¡l es el riesgo de inundaciÃ³n en El Danubio?&rdquo;</li>
            <li>&ldquo;Â¿QuÃ© hacer en caso de alerta roja?&rdquo;</li>
            <li>&ldquo;Â¿CuÃ¡ndo es temporada de lluvias?&rdquo;</li>
            <li>&ldquo;Â¿CÃ³mo puedo reportar una inundaciÃ³n?&rdquo;</li>
            <li>&ldquo;Â¿QuÃ© es el sistema AVCA?&rdquo;</li>
          </ul>
        </div>

        <div className={styles.info}>
          <p className="text-caption">
            ğŸ’¡ <strong>Consejo:</strong> Habla con claridad y espera la respuesta antes de hacer otra pregunta.
          </p>
        </div>
      </div>
    </div>
  );
}
